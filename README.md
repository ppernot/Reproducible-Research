# Reproducible Research

Codes and data to reproduce the results of the following papers:

* [2022_Tightness](https://github.com/ppernot/2022_Tightness)
"Prediction uncertainty validation for computational chemists" by P. Pernot (2022)
[arXiv](https://arxiv.org/abs/2204.13477)

* [2022_Confidence](https://github.com/ppernot/2022_Confidence)
"Confidence curves for UQ validation: probabilistic reference vs. oracle" by P. Pernot (2022) [arXiv](https://arxiv.org/abs/2206.15272v1)

* [PU2022](https://github.com/ppernot/PU2022)
"The long road to calibrated prediction uncertainty in computational chemistry"
by P. Pernot  (2022) [_J. Chem. Phys._ __156__:114109](https://doi.org/10.1063/5.0084302); [arXiv](https://arxiv.org/abs/2201.01511)

* [Gini](https://github.com/ppernot/Gini) 
"Using the Gini coefficient to characterize the shape of computational chemistry error distributions", by P. Pernot and A. Savin (2021) [_Theor. Chem. Acc._ __140__:24](https://doi.org/10.1007/s00214-021-02725-0); [arXiv](https://arxiv.org/abs/2012.09589) 
  
* [ML2020](https://github.com/ppernot/ML2020)
"Impact of non-normal error distributions on the benchmarking and ranking of Quantum Machine Learning models", by P. Pernot, B. Huang and A. Savin (2020) [_Machine Learning: Science and Technology_ __1__:035011](https://doi.org/10.1088/2632-2153/aba184); [arXiv](https://arxiv.org/abs/2004.02524)

* [SIP](https://github.com/ppernot/SIP)
  "Probabilistic performance estimators for computational chemistry methods: 
  Systematic Improvement Probability and Ranking Probability Matrix. I. Theory", 
  by P. Pernot and A. Savin (2020).
  [_J. Chem. Phys._ __152__:164108](http://dx.doi.org/10.1063/5.0006202);
  [arXiv](https://arxiv.org/abs/2003.00987),    
  and    
  "Probabilistic performance estimators for computational chemistry methods: 
  Systematic Improvement Probability and Ranking Probability Matrix. II. Applications", 
  by P. Pernot and A. Savin (2020).
  [_J. Chem. Phys._ __152__:164109](http://dx.doi.org/10.1063/5.0006204);
  [arXiv](https://arxiv.org/abs/2003.01572).

* [ECDFT](https://github.com/ppernot/ECDFT) 
  "Probabilistic performance estimators for computational chemistry methods: the empirical cumulative distribution function of absolute errors", by P. Pernot and A. Savin (2018) [_J. Chem. Phys._ __148__:241707](http://dx.doi.org/10.1063/1.5016248)     
  
* [PUIF](https://github.com/ppernot/PUIF) 
"The parameters uncertainty inflation fallacy", by P. Pernot (2017) [_J. Chem. Phys._ __147__:104102](http://dx.doi.org/10.1063/1.4994654); [arXiv](https://arxiv.org/abs/1611.04295)
  
* [CalPred](https://github.com/ppernot/CalPred) 
"A critical review of statistical calibration/prediction models handling data inconsistency and model  inadequacy", by P. Pernot and F. Cailliez (2017) [_AIChE J._ __63__:4642](http://dx.doi.org/10.1002/aic.15781); [arXiv](https://arxiv.org/abs/1611.04376)

* [PU_DFA](./PU_DFA)
"Prediction Uncertainty of Density Functional Approximations for Properties of Crystals with Cubic Symmetry" by P. Pernot, B. Civalleri, D. Presti and A. Savin (2015) [_J. Phys. Chem. A_ __119__:5288-5304](http://dx.doi.org/10.1021/jp509980w)

* [NegVar](./NegVar)
"Model's output variance can increase when input variance decreases: a sensitivity analysis paradox?" by P. Pernot, M. DÃ©senfant and F. Hennebelle (2015) [17th International Congress of Metrology, B. Larquier, Ed., EDP Sciences](http://dx.doi.org/10.1051/metrology/20150002004)
